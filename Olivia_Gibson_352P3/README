# Project 2 â€“ HTML Table Extractor

This project automates the extraction of HTML tables from web pages using Docker and a Python script. It downloads HTML content from a list of URLs, parses the first table found on each page, and saves the result as a CSV file. The entire workflow is containerized for consistency and reproducibility across systems.

## ğŸ“ Folder Structure

```
352P3/
â”œâ”€â”€ Dockerfile                      # Builds the Docker image
â”œâ”€â”€ extract_tables.py              # Python script to extract HTML tables
â”œâ”€â”€ extract_tables.sh              # Bash script to automate the workflow
â”œâ”€â”€ sample.html                    # Sample HTML file for local testing
â”œâ”€â”€ csv_output/                    # Output folder for extracted CSVs
â”œâ”€â”€ *.html                         # Downloaded HTML files
```

## ğŸ›  Requirements

- Docker installed and running
- Git Bash (Windows) or any Bash-compatible shell
- Internet connection (for downloading live HTML pages)

## ğŸš€ How to Run

Open Git Bash in the project folder and run:

```bash
bash extract_tables.sh "https://www.worldometers.info/world-population/population-by-country/,https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/,https://www.basketball-reference.com/leagues/NBA_2023_standings.html,https://en.wikipedia.org/wiki/Comparison_of_programming_languages"
```

This will:
1. Download each HTML page
2. Save it locally with a sanitized filename
3. Run the Docker container to extract the first table
4. Save the table as a CSV in `csv_output/`

## ğŸ§ª Sample Test

To test the pipeline locally without downloading from the web:

```bash
bash extract_tables.sh "file://$(pwd)/sample.html"
```

This will extract a table from `sample.html` and save it to `csv_output/sample_table1.csv`.

## ğŸ§¹ File Naming Convention

Each URL is converted into a safe filename using underscores. For example:

```
URL:
https://www.worldometers.info/world-population/population-by-country/

â†’ HTML:
worldometers_info_world_population_population_by_country__.html

â†’ CSV:
worldometers_info_world_population_population_by_country__table1.csv
```

## âš™ï¸ How It Works

- `extract_tables.sh` takes a comma-separated list of URLs
- Each URL is downloaded using `curl`
- Filenames are sanitized using `sed`
- Docker runs the Python script inside a container
- The first `<table>` from each HTML file is extracted
- Output is saved to `csv_output/` with `_table1.csv` suffix

## ğŸ§‘â€ğŸ« For Grading

All required files are included:
- `extract_tables.sh` â€“ main automation script
- `extract_tables.py` â€“ table extraction logic
- `Dockerfile` â€“ builds the container
- `sample.html` â€“ test input
- `csv_output/` â€“ output folder (can be emptied before grading)

To test:
1. Open Git Bash in the folder
2. Run the script with sample or live URLs
3. Check `csv_output/` for results

No additional setup is required. The script will create `csv_output/` automatically and handle all downloads and processing.

## âœ… Notes

- Only the **first table** on each page is extracted
- The script is designed to be portable and reproducible
- Works on Windows (via Git Bash), macOS, and Linux
- Docker ensures consistent behavior across environments
